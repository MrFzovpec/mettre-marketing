{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Instagramm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6Df/WOgjMAX22ZVljcEgZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrFzovpec/mettre-marketing/blob/master/marketing_analysis/instagram/Instagramm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mela96JA3uIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvGz9UoIyUBe",
        "colab_type": "text"
      },
      "source": [
        "# Organizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXIjErtpyXvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLxgQ89tyaEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/MrFzovpec/mettre-marketing/master/marketing_analysis/instagram/instagram.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06yvYKjZylHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', \n",
        "                 'Unnamed: 0.1.1.1.1', 'Unnamed: 0.1.1.1.1.1', 'Unnamed: 0.1.1.1.1.1.1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNppcZ2_ymRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrfp_WsYz62C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROwzmaJ_09LY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['index_account'] = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO2bKSo02rzK",
        "colab_type": "text"
      },
      "source": [
        "The accounts are depersonalized, so we need to indexate them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X170JvBp2Tew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_acc = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM_Bx7af0CgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in df.iterrows():\n",
        "  if x[0] == 0:\n",
        "    df['index_account'][x[0]] = index_acc\n",
        "    previous = x[1]['account_description']\n",
        "    continue\n",
        "  if x[1]['account_description'] == previous:\n",
        "    df['index_account'][x[0]] = index_acc\n",
        "  else:\n",
        "    index_acc += 1\n",
        "    df['index_account'][x[0]] = index_acc\n",
        "\n",
        "  previous = x[1]['account_description']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-MIQmmUrQwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "42afd5b0-38b0-4491-abd2-c4847d2d789f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_posts</th>\n",
              "      <th>text</th>\n",
              "      <th>likes</th>\n",
              "      <th>date</th>\n",
              "      <th>subscribers</th>\n",
              "      <th>subscribed</th>\n",
              "      <th>image_urls</th>\n",
              "      <th>account_description</th>\n",
              "      <th>index_account</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155</td>\n",
              "      <td>here‚Äôs my fire/water girl oc w butterfly sleev...</td>\n",
              "      <td>42,103</td>\n",
              "      <td>2020-06-11T20:32:23.000Z</td>\n",
              "      <td>286,674</td>\n",
              "      <td>397</td>\n",
              "      <td>https://instagram.fbru2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>üé® repost with credit!\\nüçâ clip studio paint\\nüç° ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>155</td>\n",
              "      <td>here‚Äôs a tablet vs phone challenge bc i haven‚Äô...</td>\n",
              "      <td>76,906</td>\n",
              "      <td>2020-06-09T20:35:07.000Z</td>\n",
              "      <td>286,674</td>\n",
              "      <td>397</td>\n",
              "      <td>https://instagram.fbru2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>üé® repost with credit!\\nüçâ clip studio paint\\nüç° ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155</td>\n",
              "      <td>here‚Äôs a sailor moon mermaid! ‚ú®üåäüåä i had fun dr...</td>\n",
              "      <td>42,219</td>\n",
              "      <td>2020-06-05T20:50:10.000Z</td>\n",
              "      <td>286,674</td>\n",
              "      <td>397</td>\n",
              "      <td>https://instagram.fbru2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>üé® repost with credit!\\nüçâ clip studio paint\\nüç° ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>155</td>\n",
              "      <td>here‚Äôs a support post for black artists and cr...</td>\n",
              "      <td>81,812</td>\n",
              "      <td>2020-06-03T19:20:01.000Z</td>\n",
              "      <td>286,674</td>\n",
              "      <td>397</td>\n",
              "      <td>https://instagram.fbru2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>üé® repost with credit!\\nüçâ clip studio paint\\nüç° ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155</td>\n",
              "      <td>a milk carton vending machine! decorate the co...</td>\n",
              "      <td>37,869</td>\n",
              "      <td>2020-05-28T20:37:42.000Z</td>\n",
              "      <td>286,674</td>\n",
              "      <td>397</td>\n",
              "      <td>https://instagram.fbru2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>üé® repost with credit!\\nüçâ clip studio paint\\nüç° ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  total_posts  ... index_account\n",
              "0         155  ...             0\n",
              "1         155  ...             0\n",
              "2         155  ...             0\n",
              "3         155  ...             0\n",
              "4         155  ...             0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAQSEl0YZL3G",
        "colab_type": "text"
      },
      "source": [
        "# Creating a dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssnx8BMSZjhS",
        "colab_type": "text"
      },
      "source": [
        "This is going to be an LSTM model and it's going to work with the five previous examples. So, for example I wanna predict likes countable for some particular post, then I'm going to take 4 previous posts and make a prediction basing on their data. <br> <br>\n",
        "Here I'll create a few classes which would provide that functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHxIASRrZitk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetSamples():\n",
        "  ''' This class will return a dataset samples in the format of 5 posts \n",
        "  (more or less). It's going to be kind of a sliding window'''\n",
        "  def __init__(self, df, window_size=5):\n",
        "    self.df = df\n",
        "    self.window_size = window_size\n",
        "\n",
        "  def get_window_of_posts(self):\n",
        "    users = df['index_account'].unique()\n",
        "\n",
        "    for user in users:\n",
        "      user = int(user)\n",
        "      user_df = df[df['index_account'] == user]\n",
        "      user_df_len = len(user_df)\n",
        "      user_posts_array = []\n",
        "\n",
        "      # Identifying the indexes we're going to use to parse\n",
        "      starts_index = 0\n",
        "      final_index = user_df_len - self.window_size\n",
        "\n",
        "      for index in range(starts_index, final_index):\n",
        "        # Sometimes account doesn't have even 5 posts\n",
        "        if len(user_df.iloc[index: index + self.window_size]) == 0:\n",
        "          continue\n",
        "\n",
        "        yield user_df.iloc[index: index + self.window_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHukg3Cfftkb",
        "colab_type": "text"
      },
      "source": [
        "The class above just samples a data with some particular window size and returns it in the format of generator of array of the posts (pandas df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNY7aTa7ygq4",
        "colab_type": "text"
      },
      "source": [
        "The following class is encoding the text and creating a tensor out of it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEG3e8NlWab7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import DistilBertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1WOGRzDVwoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGuk-yZtyXRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3SYdsMbv9u3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextEncoder():\n",
        "  def __init__(self, tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')):\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def encode(self, samples):\n",
        "    text_array = [] # creating a text array for keeping all the texts\n",
        "    for i, sample in samples.iteritems():\n",
        "      text_tensor = torch.tensor(self.tokenizer.encode(sample))\n",
        "      text_array.append(text_tensor)\n",
        "\n",
        "    return self.pad_and_stack(text_array)\n",
        "  \n",
        "  @staticmethod\n",
        "  def get_largest_elem(array, dim=0):\n",
        "    ''' The function identyfies the largest tensor over particular dimension '''\n",
        "    max_len = 0\n",
        "    for elem in array:\n",
        "      # Runs over thought the array to identify the largest one\n",
        "      if elem.shape[dim] > max_len:\n",
        "        max_len = elem.shape[dim]\n",
        "\n",
        "    return max_len\n",
        "\n",
        "  def pad_and_stack(self, array, dim=0):\n",
        "    ''' Function pads and stacks array over a new axis '''\n",
        "\n",
        "    if dim == 0:\n",
        "      largest = self.get_largest_elem(array) # gets the largest to pad\n",
        "      array_for_stack = []\n",
        "      for elem in array:\n",
        "        # Pad the elements to get equal shapes\n",
        "        elem = F.pad(elem, [0, largest - elem.shape[dim]])\n",
        "        array_for_stack.append(elem)\n",
        "\n",
        "    return torch.stack(array_for_stack)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCRr3VKRYjJy",
        "colab_type": "text"
      },
      "source": [
        "The following class is the class which's going to encode images out of the link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObjQgBsKdx9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLg6Hlh-eMni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zl775ZLeN-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from io import BytesIO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJGeqHligvc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iv-iG7cg6bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsVBHwUsYrmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageEncoder():\n",
        "  def __init__(self, size_index=2, transform=transforms.ToTensor()):\n",
        "    self.size_index = size_index\n",
        "    self.transform = transform\n",
        "\n",
        "  def encode(self, samples):\n",
        "    image_array = [] # creating an array for keeping all the images\n",
        "    for i, sample in samples.iteritems():\n",
        "      # Getting a clear link of an image\n",
        "      link_href = sample.split(',')[self.size_index][:-5]\n",
        "      image = self.get_img_from_remote_server(link_href)\n",
        "      image = self.transform(image)\n",
        "      image_array.append(image)\n",
        "    \n",
        "    return torch.stack(image_array)\n",
        "\n",
        "  @staticmethod\n",
        "  def get_img_from_remote_server(url):\n",
        "    ''' Function gets an image from a remote server '''\n",
        "    response = requests.get(url)\n",
        "    return Image.open(BytesIO(response.content))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WLNMzhtjFob",
        "colab_type": "text"
      },
      "source": [
        "This class will pack up a metadata into the tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-3aPL2ijL58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MetaDataEncoder():\n",
        "  def encode(self, samples):\n",
        "    meta_array = [] # creating an array for keeping all the metadata\n",
        "    for i, sample in samples.iteritems():\n",
        "      meta_array.append(torch.tensor([int(sample.replace(',',''))]))\n",
        "\n",
        "    return torch.stack(meta_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muvKSxPmj4px",
        "colab_type": "text"
      },
      "source": [
        "The following class is going to encode the date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ723Ei1r6xM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTKfKMBmrKzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DateEncoder():\n",
        "  def encode(self, samples):\n",
        "    date_array = []\n",
        "\n",
        "    for i, sample in samples.iteritems():\n",
        "      date = datetime.strptime(sample, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "      date = date.timestamp()\n",
        "      date_array.append(torch.tensor([date]))\n",
        "\n",
        "    return torch.stack(date_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBlOkivOpqwO",
        "colab_type": "text"
      },
      "source": [
        "The following class is going to manage the data and give the final one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l7pSjc2vzVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2mjT2-FpfIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetManager(Dataset):\n",
        "  def __init__(self, df, generator=DatasetSamples, text_encoder=TextEncoder(),\n",
        "               image_encoder=ImageEncoder(), meta_data_encoder=MetaDataEncoder(),\n",
        "               date_encoder=DateEncoder()):\n",
        "    super().__init__()\n",
        "    self.generator = generator(df)\n",
        "    self.generator = self.generator.get_window_of_posts()\n",
        "    self.data = [sample for sample in self.generator]\n",
        "\n",
        "    # Encoders for different data\n",
        "    self.text_encoder, self.account_description_encoder = text_encoder, text_encoder\n",
        "    self.image_encoder = image_encoder\n",
        "    self.date_encoder = date_encoder\n",
        "    self.likes_encoder, self.comments_encoder = meta_data_encoder, meta_data_encoder\n",
        "    self.total_posts_encoder, self.subscribers_encoder = meta_data_encoder, meta_data_encoder\n",
        "    self.subscribed_encoder = meta_data_encoder\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample_data = self.data[index]\n",
        "\n",
        "    return {\n",
        "        'total_posts': self.total_posts_encoder.encode(sample_data['total_posts']),\n",
        "        'text': self.text_encoder.encode(sample_data['text']),\n",
        "        'likes': self.likes_encoder.encode(sample_data['likes']),\n",
        "        'date': self.date_encoder.encode(sample_data['date']),\n",
        "        'image': self.image_encoder.encode(sample_data['image_urls']),\n",
        "        'subscribers': self.subscribers_encoder.encode(sample_data['subscribers']),\n",
        "        'subscribed': self.subscribed_encoder.encode(sample_data['subscribed']),\n",
        "        'account_description': self.account_description_encoder.encode(sample_data['account_description']),\n",
        "    }\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2TC88lxzhlR",
        "colab_type": "text"
      },
      "source": [
        "# Creating a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5sKYL_FcBO6",
        "colab_type": "text"
      },
      "source": [
        "The first version of the model is going to be an analysing LSTM model, which will analyse the last five posts and make the predictions about last one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsaLd2QDznwP",
        "colab_type": "text"
      },
      "source": [
        "At first we will create a model for the text analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpF_02HE2LlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGHGMnJD2aiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import DistilBertModel"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-tPrmT02PTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DistilBERTAnalysis(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.transformer = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
        "    self.linear = nn.Linear(3072, 64)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.transformer(x)\n",
        "    x = x[0][:, :4, :]\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.linear(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-2wAhch3fnK",
        "colab_type": "text"
      },
      "source": [
        "The next model will be a model for images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6KNT4G_VScg",
        "colab_type": "text"
      },
      "source": [
        "The first model for the image classification is going to be a VGG model as far as it gives really meaningfull vector on its top:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6TzYcxO3nw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60aGc2IU4OAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionV3Analysis(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.imager = models.vgg19_bn(pretrained=False)\n",
        "    self.imager.classifier = nn.Linear(25088, 64)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.imager(x)"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6ZTgpEfWZCN",
        "colab_type": "text"
      },
      "source": [
        "The following class is going to get a representational vector for the meta data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i0yl1XxWhpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MetaLinearAnalyzator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(4, 32)\n",
        "    self.linear2 = nn.Linear(32, 64)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = F.leaky_relu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = F.leaky_relu(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMELuN7AbDzY",
        "colab_type": "text"
      },
      "source": [
        "This class is going to recieve all the contexual vectors and make another contexual vector which is going to be passed to the following LSTM cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yu40Q19cY06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ContexualVectorCreator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(256, 512)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs8QC4tdkdH_",
        "colab_type": "text"
      },
      "source": [
        "It's an LSTM class, which going to finally give out a class prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H61M-k5nkofT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMPredictor(nn.Module):\n",
        "  def __init__(self, memory_depth=512):\n",
        "    self.memory_depth = memory_depth\n",
        "    self.lstm_cell = nn.LSTMCell(512, self.memory_depth)\n",
        "\n",
        "  def forward(self, x):\n",
        "    ''' \n",
        "      !IMPORTANT: the function recieves an ARRAY OF TENSORS. NOT TORCH TENSOR\n",
        "      Needs to write a part with a likes plussing \n",
        "    '''\n",
        "    c_0 = self.get_first_cell_state(1)\n",
        "    for i, vector in enumerate(x):\n",
        "      h_0, c_0 = self.lstm_cell(vector, c_0)\n",
        "      if len(x) - 1 == \n",
        "\n",
        "  def get_first_cell_state(self, samples_countable):\n",
        "    return torch.zeros((samples_countable, self.memory_depth))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOwRMU-w4MyY",
        "colab_type": "text"
      },
      "source": [
        "And here it is. This is the final model which is going to get predictions basing on the contexual vectors from the previous posts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLmJzjFHzlhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pytorch_lightning as pl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoWplG-D2EK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EnsembledModelPredictor(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.text = DistilBERTAnalysis()\n",
        "    self.images = InceptionV3Analysis()\n",
        "    self.meta = MetaLinearAnalyzator()\n",
        "\n",
        "  def forward(self, x):\n",
        "    ''' Needs to rethink the architecture of the model '''\n",
        "    text, acc_description = x['text'], x['account_description']\n",
        "\n",
        "  def training_step(self):\n",
        "    ''' So, here we will prepare and send the data to the post ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxuyFC2I2JWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}