{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Instagramm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjgTXFFaEspnIzSZbECVki",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b6444f0d69014358883439c8f674fd77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4de15bb3537404cb482cef6f9fd3e3c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_73680b1c822842b8953058027cfb9103",
              "IPY_MODEL_56fd668691244ec581e7cb10f6c36979"
            ]
          }
        },
        "c4de15bb3537404cb482cef6f9fd3e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73680b1c822842b8953058027cfb9103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9bd84703d8054913a8b97a73ae8be856",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b944b4c01728428f8ba5c562bad069e1"
          }
        },
        "56fd668691244ec581e7cb10f6c36979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a2b38bc625ba47c49003506e02e2eb43",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 4.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1aa9de5e5ea347479c75ec664772530c"
          }
        },
        "9bd84703d8054913a8b97a73ae8be856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b944b4c01728428f8ba5c562bad069e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2b38bc625ba47c49003506e02e2eb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1aa9de5e5ea347479c75ec664772530c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64d1ba35a03b4d15b62c16aeede0df61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bf85be87a95240b98bd5b0a75820f6bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75b7f9e924724d088fb8485f9ff1e18f",
              "IPY_MODEL_4f5e4d6184764adfa337b2f04b02200c"
            ]
          }
        },
        "bf85be87a95240b98bd5b0a75820f6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "75b7f9e924724d088fb8485f9ff1e18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_933e828e7a1d41808b0a43b8b34f3515",
            "_dom_classes": [],
            "description": "Epoch 3:   1%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 2486,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 31,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03730e23b9b443678e240c257e9c8f44"
          }
        },
        "4f5e4d6184764adfa337b2f04b02200c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f144f168020b450794364ab1e6356079",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 31/2486 [01:56&lt;2:34:25,  3.77s/it, loss=311794.531, v_num=3]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac56fc256422469ca32b7ba94b12bb01"
          }
        },
        "933e828e7a1d41808b0a43b8b34f3515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03730e23b9b443678e240c257e9c8f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f144f168020b450794364ab1e6356079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac56fc256422469ca32b7ba94b12bb01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrFzovpec/mettre-marketing/blob/master/marketing_analysis/instagram/Instagramm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mela96JA3uIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvGz9UoIyUBe",
        "colab_type": "text"
      },
      "source": [
        "# Organizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXIjErtpyXvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLxgQ89tyaEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/MrFzovpec/mettre-marketing/master/marketing_analysis/instagram/instagram.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06yvYKjZylHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', \n",
        "                 'Unnamed: 0.1.1.1.1', 'Unnamed: 0.1.1.1.1.1', 'Unnamed: 0.1.1.1.1.1.1'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNppcZ2_ymRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrfp_WsYz62C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop_duplicates()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROwzmaJ_09LY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['index_account'] = None"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO2bKSo02rzK",
        "colab_type": "text"
      },
      "source": [
        "The accounts are depersonalized, so we need to indexate them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X170JvBp2Tew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_acc = 0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM_Bx7af0CgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in df.iterrows():\n",
        "  if x[0] == 0:\n",
        "    df['index_account'][x[0]] = index_acc\n",
        "    previous = x[1]['account_description']\n",
        "    continue\n",
        "  if x[1]['account_description'] == previous:\n",
        "    df['index_account'][x[0]] = index_acc\n",
        "  else:\n",
        "    index_acc += 1\n",
        "    df['index_account'][x[0]] = index_acc\n",
        "\n",
        "  previous = x[1]['account_description']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-MIQmmUrQwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "7f9ae525-9130-415a-ed0e-f5587aacdb3f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_posts</th>\n",
              "      <th>text</th>\n",
              "      <th>likes</th>\n",
              "      <th>date</th>\n",
              "      <th>subscribers</th>\n",
              "      <th>subscribed</th>\n",
              "      <th>image_urls</th>\n",
              "      <th>account_description</th>\n",
              "      <th>index_account</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155</td>\n",
              "      <td>here‚Äôs my fire/water girl oc w butterfly sleev...</td>\n",
              "      <td>42,103</td>\n",
              "      <td>2020-06-11T20:32:23.000Z</td>\n",
              "      <td>286,674</td>\n",
              "      <td>397</td>\n",
              "      <td>https://instagram.fbru2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>üé® repost with credit!\\nüçâ clip studio paint\\nüç° ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>155</td>\n",
              "      <td>here‚Äôs a tablet vs phone challenge bc i haven‚Äô...</td>\n",
              "      <td>76,906</td>\n",
              "      <td>2020-06-09T20:35:07.000Z</td>\n",
              "      <td>286,674</td>\n",
              "      <td>397</td>\n",
              "      <td>https://instagram.fbru2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>üé® repost with credit!\\nüçâ clip studio paint\\nüç° ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155</td>\n",
              "      <td>here‚Äôs a sailor moon mermaid! ‚ú®üåäüåä i had fun dr...</td>\n",
              "      <td>42,219</td>\n",
              "      <td>2020-06-05T20:50:10.000Z</td>\n",
              "      <td>286,674</td>\n",
              "      <td>397</td>\n",
              "      <td>https://instagram.fbru2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>üé® repost with credit!\\nüçâ clip studio paint\\nüç° ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>155</td>\n",
              "      <td>here‚Äôs a support post for black artists and cr...</td>\n",
              "      <td>81,812</td>\n",
              "      <td>2020-06-03T19:20:01.000Z</td>\n",
              "      <td>286,674</td>\n",
              "      <td>397</td>\n",
              "      <td>https://instagram.fbru2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>üé® repost with credit!\\nüçâ clip studio paint\\nüç° ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155</td>\n",
              "      <td>a milk carton vending machine! decorate the co...</td>\n",
              "      <td>37,869</td>\n",
              "      <td>2020-05-28T20:37:42.000Z</td>\n",
              "      <td>286,674</td>\n",
              "      <td>397</td>\n",
              "      <td>https://instagram.fbru2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>üé® repost with credit!\\nüçâ clip studio paint\\nüç° ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  total_posts  ... index_account\n",
              "0         155  ...             0\n",
              "1         155  ...             0\n",
              "2         155  ...             0\n",
              "3         155  ...             0\n",
              "4         155  ...             0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAQSEl0YZL3G",
        "colab_type": "text"
      },
      "source": [
        "# Creating a dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssnx8BMSZjhS",
        "colab_type": "text"
      },
      "source": [
        "This is going to be an LSTM model and it's going to work with the five previous examples. So, for example I wanna predict likes countable for some particular post, then I'm going to take 4 previous posts and make a prediction basing on their data. <br> <br>\n",
        "Here I'll create a few classes which would provide that functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHxIASRrZitk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetSamples():\n",
        "  ''' This class will return a dataset samples in the format of 5 posts \n",
        "  (more or less). It's going to be kind of a sliding window'''\n",
        "  def __init__(self, df, window_size=5):\n",
        "    self.df = df\n",
        "    self.window_size = window_size\n",
        "\n",
        "  def get_window_of_posts(self):\n",
        "    users = df['index_account'].unique()\n",
        "\n",
        "    for user in users:\n",
        "      user = int(user)\n",
        "      user_df = df[df['index_account'] == user]\n",
        "      user_df_len = len(user_df)\n",
        "      user_posts_array = []\n",
        "\n",
        "      # Identifying the indexes we're going to use to parse\n",
        "      starts_index = 0\n",
        "      final_index = user_df_len - self.window_size\n",
        "\n",
        "      for index in range(starts_index, final_index):\n",
        "        # Sometimes account doesn't have even 5 posts\n",
        "        if len(user_df.iloc[index: index + self.window_size]) == 0:\n",
        "          continue\n",
        "\n",
        "        yield user_df.iloc[index: index + self.window_size]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHukg3Cfftkb",
        "colab_type": "text"
      },
      "source": [
        "The class above just samples a data with some particular window size and returns it in the format of generator of array of the posts (pandas df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNY7aTa7ygq4",
        "colab_type": "text"
      },
      "source": [
        "The following class is encoding the text and creating a tensor out of it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEG3e8NlWab7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import DistilBertTokenizer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1WOGRzDVwoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGuk-yZtyXRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3SYdsMbv9u3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b6444f0d69014358883439c8f674fd77",
            "c4de15bb3537404cb482cef6f9fd3e3c",
            "73680b1c822842b8953058027cfb9103",
            "56fd668691244ec581e7cb10f6c36979",
            "9bd84703d8054913a8b97a73ae8be856",
            "b944b4c01728428f8ba5c562bad069e1",
            "a2b38bc625ba47c49003506e02e2eb43",
            "1aa9de5e5ea347479c75ec664772530c"
          ]
        },
        "outputId": "62770f10-758e-4a3d-cc42-cd0d271a5f7f"
      },
      "source": [
        "class TextEncoder():\n",
        "  def __init__(self, tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')):\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def encode(self, samples):\n",
        "    text_array = [] # creating a text array for keeping all the texts\n",
        "    for i, sample in samples.iteritems():\n",
        "      text_tensor = torch.tensor(self.tokenizer.encode(sample))\n",
        "      text_array.append(text_tensor)\n",
        "\n",
        "    return self.pad_and_stack(text_array)\n",
        "  \n",
        "  @staticmethod\n",
        "  def get_largest_elem(array, dim=0):\n",
        "    ''' The function identyfies the largest tensor over particular dimension '''\n",
        "    max_len = 0\n",
        "    for elem in array:\n",
        "      # Runs over thought the array to identify the largest one\n",
        "      if elem.shape[dim] > max_len:\n",
        "        max_len = elem.shape[dim]\n",
        "\n",
        "    return max_len\n",
        "\n",
        "  def pad_and_stack(self, array, dim=0):\n",
        "    ''' Function pads and stacks array over a new axis '''\n",
        "\n",
        "    if dim == 0:\n",
        "      largest = self.get_largest_elem(array) # gets the largest to pad\n",
        "      array_for_stack = []\n",
        "      for elem in array:\n",
        "        # Pad the elements to get equal shapes\n",
        "        elem = F.pad(elem, [0, largest - elem.shape[dim]])\n",
        "        array_for_stack.append(elem)\n",
        "\n",
        "    return torch.stack(array_for_stack)\n",
        "      "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6444f0d69014358883439c8f674fd77",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCRr3VKRYjJy",
        "colab_type": "text"
      },
      "source": [
        "The following class is the class which's going to encode images out of the link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObjQgBsKdx9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLg6Hlh-eMni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zl775ZLeN-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from io import BytesIO"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJGeqHligvc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iv-iG7cg6bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsVBHwUsYrmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageEncoder():\n",
        "  def __init__(self, size_index=2, transform=transforms.ToTensor()):\n",
        "    self.size_index = size_index\n",
        "    self.transform = transform\n",
        "\n",
        "  def encode(self, samples):\n",
        "    image_array = [] # creating an array for keeping all the images\n",
        "    for i, sample in samples.iteritems():\n",
        "      # Getting a clear link of an image\n",
        "      link_href = sample.split(',')[self.size_index][:-5]\n",
        "      image = self.get_img_from_remote_server(link_href)\n",
        "      image = self.transform(image)\n",
        "      image_array.append(image)\n",
        "    \n",
        "    return torch.stack(image_array)\n",
        "\n",
        "  @staticmethod\n",
        "  def get_img_from_remote_server(url):\n",
        "    ''' Function gets an image from a remote server '''\n",
        "    response = requests.get(url)\n",
        "    return Image.open(BytesIO(response.content))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WLNMzhtjFob",
        "colab_type": "text"
      },
      "source": [
        "This class will pack up a metadata into the tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-3aPL2ijL58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MetaDataEncoder():\n",
        "  def encode(self, samples):\n",
        "    meta_array = [] # creating an array for keeping all the metadata\n",
        "    for i, sample in samples.iteritems():\n",
        "      meta_array.append(torch.tensor([int(sample.replace(',',''))], dtype=torch.float))\n",
        "\n",
        "    return torch.stack(meta_array)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muvKSxPmj4px",
        "colab_type": "text"
      },
      "source": [
        "The following class is going to encode the date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ723Ei1r6xM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTKfKMBmrKzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DateEncoder():\n",
        "  def encode(self, samples):\n",
        "    date_array = []\n",
        "\n",
        "    for i, sample in samples.iteritems():\n",
        "      date = datetime.strptime(sample, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "      date = date.timestamp()\n",
        "      date_array.append(torch.tensor([date], dtype=torch.float))\n",
        "\n",
        "    return torch.stack(date_array)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57zf7H31xAij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBlOkivOpqwO",
        "colab_type": "text"
      },
      "source": [
        "The following class is going to manage the data and give the final one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l7pSjc2vzVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2mjT2-FpfIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetManager(Dataset):\n",
        "  def __init__(self, df, generator=DatasetSamples, text_encoder=TextEncoder(),\n",
        "               image_encoder=ImageEncoder(), meta_data_encoder=MetaDataEncoder(),\n",
        "               date_encoder=DateEncoder()):\n",
        "    super().__init__()\n",
        "    self.generator = generator(df)\n",
        "    self.generator = self.generator.get_window_of_posts()\n",
        "    self.data = [sample for sample in self.generator]\n",
        "    random.shuffle(self.data)\n",
        "\n",
        "    # Encoders for different data\n",
        "    self.text_encoder, self.account_description_encoder = text_encoder, text_encoder\n",
        "    self.image_encoder = image_encoder\n",
        "    self.date_encoder = date_encoder\n",
        "    self.likes_encoder, self.comments_encoder = meta_data_encoder, meta_data_encoder\n",
        "    self.total_posts_encoder, self.subscribers_encoder = meta_data_encoder, meta_data_encoder\n",
        "    self.subscribed_encoder = meta_data_encoder\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample_data = self.data[index]\n",
        "\n",
        "    return {\n",
        "        'total_posts': self.total_posts_encoder.encode(sample_data['total_posts']),\n",
        "        'text': self.text_encoder.encode(sample_data['text']),\n",
        "        'likes': self.likes_encoder.encode(sample_data['likes']),\n",
        "        'date': self.date_encoder.encode(sample_data['date']),\n",
        "        'image': self.image_encoder.encode(sample_data['image_urls']),\n",
        "        'subscribers': self.subscribers_encoder.encode(sample_data['subscribers']),\n",
        "        'subscribed': self.subscribed_encoder.encode(sample_data['subscribed']),\n",
        "        'account_description': self.account_description_encoder.encode(sample_data['account_description']),\n",
        "    }\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2TC88lxzhlR",
        "colab_type": "text"
      },
      "source": [
        "# Creating a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5sKYL_FcBO6",
        "colab_type": "text"
      },
      "source": [
        "The first version of the model is going to be an analysing LSTM model, which will analyse the last five posts and make the predictions about last one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsaLd2QDznwP",
        "colab_type": "text"
      },
      "source": [
        "At first we will create a model for the text analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpF_02HE2LlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGHGMnJD2aiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import DistilBertModel"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-tPrmT02PTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DistilBERTAnalysis(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.transformer = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
        "    self.linear = nn.Linear(3072, 64)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.transformer(x)\n",
        "    x = x[0][:, :4, :]\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.linear(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-2wAhch3fnK",
        "colab_type": "text"
      },
      "source": [
        "The next model will be a model for images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6KNT4G_VScg",
        "colab_type": "text"
      },
      "source": [
        "The first model for the image classification is going to be a VGG model as far as it gives really meaningfull vector on its top:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6TzYcxO3nw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60aGc2IU4OAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionV3Analysis(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.imager = models.vgg19_bn(pretrained=False)\n",
        "    self.imager.classifier = nn.Linear(25088, 64)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.imager(x)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6ZTgpEfWZCN",
        "colab_type": "text"
      },
      "source": [
        "The following class is going to get a representational vector for the meta data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i0yl1XxWhpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MetaLinearAnalyzator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(4, 32)\n",
        "    self.linear2 = nn.Linear(32, 64)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = F.leaky_relu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = F.leaky_relu(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMELuN7AbDzY",
        "colab_type": "text"
      },
      "source": [
        "This class is going to recieve all the contexual vectors and make another contexual vector which is going to be passed to the following LSTM cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yu40Q19cY06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AllToOneContext(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(256, 512)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs8QC4tdkdH_",
        "colab_type": "text"
      },
      "source": [
        "It's an LSTM class, which going to finally give out a class prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H61M-k5nkofT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMPredictor(nn.Module):\n",
        "  def __init__(self, memory_depth=512):\n",
        "    super().__init__()\n",
        "    self.memory_depth = memory_depth\n",
        "    self.lstm_cell = nn.LSTMCell(512, self.memory_depth)\n",
        "\n",
        "  def forward(self, x, likes_context):\n",
        "\n",
        "    # This one gets a first memory cell vector\n",
        "    c_0 = self.get_first_cell_state(1)\n",
        "    h_0 = self.get_first_cell_state(1)\n",
        "\n",
        "    for i, vector in enumerate(x):\n",
        "      vector = torch.reshape(vector, (1, 512))\n",
        "      h_0, c_0 = self.lstm_cell(vector, (h_0, c_0))\n",
        "\n",
        "      # Checks if it's the last tensor => no likes plusage\n",
        "      if len(x) - 1 == i:\n",
        "        break\n",
        "\n",
        "      h_0 += likes_context[i]\n",
        "\n",
        "    return h_0\n",
        "\n",
        "  def get_first_cell_state(self, samples_countable):\n",
        "    return torch.zeros((samples_countable, self.memory_depth)).cuda()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOwRMU-w4MyY",
        "colab_type": "text"
      },
      "source": [
        "And here it is. This is the final model which is going to get predictions basing on the contexual vectors from the previous posts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llq8u7edptGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLmJzjFHzlhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pytorch_lightning as pl"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcNuU6jjtoEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoWplG-D2EK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EnsembledModelPredictor(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.text = DistilBERTAnalysis()\n",
        "    self.images = InceptionV3Analysis()\n",
        "    self.meta = MetaLinearAnalyzator()\n",
        "    self.all_to_one = AllToOneContext()\n",
        "    self.likes = nn.Linear(1, 512)\n",
        "    self.lstmer = LSTMPredictor()\n",
        "    self.predictor = nn.Linear(512, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    ''' Needs to rethink the architecture of the model '''\n",
        "\n",
        "    # Getting information about text\n",
        "    text, acc_description = x['text'][0], x['account_description'][0]\n",
        "    text, acc_description = text[:, :512], acc_description[:, :512]\n",
        "    text_context, acc_description_context = self.text(text), self.text(acc_description)\n",
        "\n",
        "    # Getting the information about images\n",
        "    image = x['image'][0]\n",
        "    image_context = self.images(image)\n",
        "\n",
        "    # Getting the information about the account meta data\n",
        "    total_posts, subscribers = x['total_posts'][0], x['subscribers'][0]\n",
        "    date, subscribed = x['date'][0], x['subscribed'][0]\n",
        "    meta_data_tensor = torch.cat([total_posts, subscribers, date, subscribed], dim=1)\n",
        "    meta_context = self.meta(meta_data_tensor)\n",
        "\n",
        "    # Getting the information about all the posts and likes\n",
        "    context_vector = torch.cat([text_context, acc_description_context, \n",
        "                                image_context, meta_context], dim=1)\n",
        "    context_vector = self.all_to_one(context_vector)\n",
        "    likes_vector = self.likes(x['likes'][0])\n",
        "\n",
        "    # Getting LSTM context and final prediction\n",
        "    context_result = self.lstmer(context_vector, likes_vector)\n",
        "    prediction = self.predictor(context_result)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "  def prepare_data(self):\n",
        "    self.train_ds = DatasetManager(df)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_ds)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = optim.Adam(self.parameters(), 1e-3)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 1000)\n",
        "    return [optimizer], [scheduler]\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    output = self.forward(batch)\n",
        "\n",
        "    # Getting the y\n",
        "    y = batch['likes'][0]\n",
        "    y = y[y.shape[0] - 1]\n",
        "    y = torch.reshape(y, (1, y.shape[0]))\n",
        "\n",
        "    loss_f = F.mse_loss(output, y)\n",
        "    logs = {'train_loss': loss_f}\n",
        "    return {'loss': loss_f, 'log': logs}"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIoxl46hf4ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = EnsembledModelPredictor()"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InEt7qwYtd45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_lightning import Trainer"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5yvrX8ztfPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b7181410-2f45-43d5-a0e5-15441c2118c0"
      },
      "source": [
        "trainer = Trainer(gpus=1)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cS1G8DfthX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733,
          "referenced_widgets": [
            "64d1ba35a03b4d15b62c16aeede0df61",
            "bf85be87a95240b98bd5b0a75820f6bf",
            "75b7f9e924724d088fb8485f9ff1e18f",
            "4f5e4d6184764adfa337b2f04b02200c",
            "933e828e7a1d41808b0a43b8b34f3515",
            "03730e23b9b443678e240c257e9c8f44",
            "f144f168020b450794364ab1e6356079",
            "ac56fc256422469ca32b7ba94b12bb01"
          ]
        },
        "outputId": "06d0c305-871e-425f-9f0c-0f2d8a5a4873"
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name       | Type                 | Params\n",
            "----------------------------------------------------\n",
            "0 | text       | DistilBERTAnalysis   | 134 M \n",
            "1 | images     | InceptionV3Analysis  | 21 M  \n",
            "2 | meta       | MetaLinearAnalyzator | 2 K   \n",
            "3 | all_to_one | AllToOneContext      | 131 K \n",
            "4 | likes      | Linear               | 1 K   \n",
            "5 | lstmer     | LSTMPredictor        | 2 M   \n",
            "6 | predictor  | Linear               | 513   \n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:24: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 2 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64d1ba35a03b4d15b62c16aeede0df61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (757 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-45d4afebefac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no-cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreinit_scheduler_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpu_core_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     def test(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# RUN TRAIN STEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0m_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0mbatch_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_step_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;31m# check if loss or model weights are nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    595\u001b[0m                                                                     opt_idx, self.hiddens)\n\u001b[1;32m    596\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m                             \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                         \u001b[0;31m# format and reduce outputs accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_forward\u001b[0;34m(self, batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfer_batch_to_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;31m# TPU support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-8ab235855166>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Getting the y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-8ab235855166>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'account_description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_description\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtext_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_description_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Getting the information about images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-a5ac9c2137f6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [5 x 2304], m2: [3072 x 64] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:283"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NecpVaWIwPur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}